# ISL Translation - Laptop Training Config (8GB VRAM)
# For parallel training with server

model:
  i3d_pretrained: null  # No pretrained weights (saves memory)
  freeze_i3d: true
  lstm_hidden: 256
  lstm_layers: 1
  lstm_dropout: 0.4
  bidirectional: true
  t5_model: "t5-small"
  max_target_length: 40

training:
  batch_size: 2           # Small for 8GB
  accumulation_steps: 4   # Effective batch = 8
  learning_rate: 3.0e-5   # Lower for stability
  weight_decay: 0.02
  epochs: 50              # Full training
  early_stopping_patience: 10
  save_every_n_epochs: 5

stability:
  gradient_clip: 0.5
  warmup_steps: 200
  mixed_precision: false  # Disabled for stability
  nan_skip: true
  nan_patience: 50

data:
  num_frames: 16
  frame_size: 112
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  num_workers: 0  # Windows

paths:
  dataset_dir: "data/isl_clstr/ISL_CSLRT_Corpus/ISL_CSLRT_Corpus/Videos_Sentence_Level"
  checkpoint_dir: "checkpoints"
  log_dir: "logs"

evaluation:
  beam_size: 2
  length_penalty: 0.6
